<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>Wachunga</title>
        <link>http://wachunga.com/</link>
        <description>Notes and ramblings on hacking and finance</description>
        <language>en-us</language>
        <pubDate>Tue, 23 Sep 2014 00:00:00 +0100</pubDate>
        
        <item>
            <link>http://wachunga.com/2014/09/23/get_your_fix_in_the_cloud.html</link>
            <guid>http://wachunga.com/2014/09/23/get_your_fix_in_the_cloud.html</guid>
            <title><![CDATA[Get your FIX in the cloud]]></title>
            <description><![CDATA[<h1>Get your FIX in the cloud</h1>
<p>The need arose recently to setup a client with an AWS EC2 based FIX connection
to the LSE via a Proquote VPN. The Proquote VPN connection must be initiated by
the client which rules out an AWS VPC connection (which is receive only). We
chose a software VPN, OpenSwan to initiate the connection to Proquote.</p>
<p>Amazon EC2 only allows TCP/UDP and ICMP therefore IPSec’s ESP and AH headers
will be blocked, forcing us to use an encapsulated IPSec connection over UDP.
Ensure that the Proquote side is configured in IPSec tunneling mode.</p>
<p>The version of OpenSwan which we had success with was Linux Openswan
U2.6.41-4-gd5ce941/K3.2.0-64-virtual from source, check that this Git hash has
been released into your version of OpenSwan.</p>
<p>Given a valid OpenSwan install on a debian based Linux, the following script
will setup the OpenSwan connection initiated from EC2.</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="c"># following https://gist.github.com/winhamwr/2871257</span>
<span class="c">#</span>
<span class="c"># EC2 security groups: open UDP access on 500 and 4500</span>
<span class="c">#</span>
<span class="c"># IPSec version used with success: Linux Openswan U2.6.41-4-gd5ce941/K3.2.0-64-virtual (netkey)</span>

<span class="nv">ELASTIC_IP</span><span class="o">=</span><span class="s2">"&lt;your ip&gt;"</span>
<span class="nv">SOURCE_IP</span><span class="o">=</span><span class="s2">"${ELASTIC_IP}"</span>
<span class="nv">CONN_NAME</span><span class="o">=</span><span class="s2">"LSE_Proquote"</span>
<span class="nv">SECURE_PSK</span><span class="o">=</span><span class="s2">"&lt;your psk&gt;"</span>
<span class="nv">RIGHT_PUBLIC_IP</span><span class="o">=</span><span class="s2">"&lt;proqute public ip&gt;"</span>
<span class="nv">RIGHT_SUBNET</span><span class="o">=</span><span class="s2">"&lt;proquote internal ip&gt;"</span>

sudo apt-get install -y openswan
<span class="c">#sudo ipsec verify  # Throws warnings as EC2 uses NETKEY Ipsec kernel stack</span>

sudo mv /etc/sysctl.conf /etc/sysctl.conf.bak

cat &gt; sysctl.conf <span class="s">&lt;&lt; ENDMSG</span>
<span class="s">net.ipv4.ip_forward=1</span>

<span class="s">net.ipv4.conf.default.send_redirects = 0</span>
<span class="s">net.ipv4.conf.all.send_redirects = 0</span>
<span class="s">net.ipv4.conf.eth0.send_redirects = 0</span>

<span class="s">net.ipv4.conf.all.accept_redirects = 0</span>
<span class="s">net.ipv4.conf.default.accept_redirects = 0</span>
<span class="s">net.ipv4.conf.eth0.accept_redirects = 0</span>
<span class="s">ENDMSG</span>

sudo mv sysctl.conf /etc/sysctl.conf
sudo sysctl -p /etc/sysctl.conf

<span class="c">#sudo ipsec verify  # should now have no ERRORS</span>

<span class="c"># Main config file</span>
cat &gt; ipsec.conf <span class="s">&lt;&lt; ENDMSG</span>
<span class="s">version 2.0</span>

<span class="s">config setup</span>
<span class="s">    nat_traversal=yes</span>
<span class="s">    protostack=netkey</span>
<span class="s">    virtual_private=%v4:10.0.0.0/8,%v4:172.16.0.0/12,%v4:192.168.0.0/16,%v4:!192.168.5.0/24</span>
<span class="s">    oe=off</span>

<span class="s">include /etc/ipsec.d/*.conf</span>
<span class="s">ENDMSG</span>

sudo mv ipsec.conf /etc/.


<span class="c"># Connection specific config.</span>
cat &gt; <span class="nv">$CONN_NAME</span>.conf <span class="s">&lt;&lt; ENDMSG</span>
<span class="s">conn $CONN_NAME</span>
<span class="s">    type=tunnel</span>
<span class="s">    authby=secret</span>
<span class="s">    left=%defaultroute</span>
<span class="s">    leftsourceip=$SOURCE_IP</span>
<span class="s">    leftid=$ELASTIC_IP</span>
<span class="s">    leftnexthop=%defaultroute</span>
<span class="s">    right=$RIGHT_PUBLIC_IP</span>
<span class="s">    rightid=$RIGHT_PUBLIC_IP</span>
<span class="s">    rightsubnet=$RIGHT_SUBNET</span>
<span class="s">    esp=aes192-sha1</span>
<span class="s">    keyexchange=ike</span>
<span class="s">    ike=aes192-sha1</span>
<span class="s">    salifetime=43200s</span>
<span class="s">    pfs=yes</span>
<span class="s">    auto=start</span>
<span class="s">    dpdaction=restart</span>
<span class="s">    forceencaps=yes</span>
<span class="s">ENDMSG</span>

sudo mv <span class="nv">$CONN_NAME</span>.conf /etc/ipsec.d/.

<span class="c"># Ipsec.secrets</span>
cat &gt; ipsec.secrets <span class="s">&lt;&lt; ENDMSG</span>
<span class="s">$ELASTIC_IP $RIGHT_PUBLIC_IP: PSK "$SECURE_PSK"</span>
<span class="s">ENDMSG</span>
sudo mv ipsec.secrets /etc/.
</pre></div>
</div>
]]></description>
            <category><![CDATA[ finance ]]></category>
             <pubDate>Tue, 23 Sep 2014 00:00:00 +0100</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2014/06/04/add_flippa_auction_to_calendar.html</link>
            <guid>http://wachunga.com/2014/06/04/add_flippa_auction_to_calendar.html</guid>
            <title><![CDATA[Add Flippa auction to calendar]]></title>
            <description><![CDATA[<h1>Add Flippa auction to calendar</h1>
<p>This is a nasty hack to add a link to Flippa which will put you on the road to
adding an event to your Google Calendar at the auction end time. Add the
following javascript as a Bookmarklet:</p>
<div class="highlight-javascript"><div class="highlight"><pre><span class="nx">javascript</span><span class="o">:</span><span class="k">void</span><span class="p">(</span><span class="nx">$</span><span class="p">(</span> <span class="s2">"#auctionstatus"</span> <span class="p">).</span><span class="nx">append</span><span class="p">(</span> <span class="s2">"&lt;a href='"</span> <span class="o">+</span> <span class="s2">"http://google.co.uk/search?q="</span> <span class="o">+</span> <span class="nb">encodeURI</span><span class="p">(</span><span class="s2">"google calendar add "</span> <span class="o">+</span> <span class="nx">$</span><span class="p">(</span><span class="s2">"#auctionstatus"</span><span class="p">).</span><span class="nx">attr</span><span class="p">(</span><span class="s2">"title"</span><span class="p">).</span><span class="nx">substr</span><span class="p">(</span><span class="mi">41</span><span class="p">,</span> <span class="mi">19</span><span class="p">))</span> <span class="o">+</span> <span class="s2">"'&gt;Add to calendar&lt;/a&gt;"</span><span class="p">));</span>
</pre></div>
</div>
]]></description>
             <pubDate>Wed, 04 Jun 2014 00:00:00 +0100</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2014/03/10/time_tracking_tool.html</link>
            <guid>http://wachunga.com/2014/03/10/time_tracking_tool.html</guid>
            <title><![CDATA[Time tracking tool]]></title>
            <description><![CDATA[<h1>Time tracking tool</h1>
<p>Another working methodology post, in order to remind me of which tool I used.
In order to keep track of tasks and time spent when in the commandline (where I
am most of the time) <a class="reference external" href="https://bitbucket.org/trevor/timebook/wiki/Home">TimeBook</a> is a great tool. It allows
you do:</p>
<div class="highlight-python"><div class="highlight"><pre>t in "task i am working on"
&lt;do some work&gt;
t out
</pre></div>
</div>
<p>Then there will be an entry in your <cite>timesheet</cite> with today’s date and the time
spent working on the task.</p>
]]></description>
             <pubDate>Mon, 10 Mar 2014 00:00:00 +0000</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2014/03/05/updating_my_web_stack.html</link>
            <guid>http://wachunga.com/2014/03/05/updating_my_web_stack.html</guid>
            <title><![CDATA[Updating my web design stack]]></title>
            <description><![CDATA[<h1>Updating my web design stack</h1>
<p>For data intensive and service related projects I always prefer to use the
simplicity of <a class="reference external" href="http://www.tornadoweb.org/en/stable">Tornado</a>. Recently I had
occasion to consider a more classic CMS type of application. I looked at Django
a number of years ago and was largely unimpressed, probably because the need at
the time was not for a CMS platform and the design of the admin interface
seemed a bit late 90’s.</p>
<p>My opinion has changed however with the <a class="reference external" href="https://github.com/torchbox/wagtail">Wagtail</a> project from Torchbox. Very nice design
and some of the key Django apps, like South, bundled in.</p>
<p>Also, I have been impressed with the <a class="reference external" href="http://bower.io">Bower</a> project -
which provides a package manager for front end components on <a class="reference external" href="http://nodejs.org">Node</a>.</p>
<p>Anyway, to get these fancy Javascript tools working in a Python virtualenv do
the following from within a virtualenv:</p>
<div class="highlight-bash"><div class="highlight"><pre>pip install nodeenv
nodeenv --python-virtualenv  <span class="c"># activate nodeenv in the current virtualenv</span>
npm install -g bower
</pre></div>
</div>
<p>Great!</p>
]]></description>
             <pubDate>Wed, 05 Mar 2014 00:00:00 +0000</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2014/02/28/clojure_setup.html</link>
            <guid>http://wachunga.com/2014/02/28/clojure_setup.html</guid>
            <title><![CDATA[Clojure setup]]></title>
            <description><![CDATA[<h1>Clojure setup</h1>
<p>I’m having lots of fun learning Clojure. There are a couple of decent ways to
be productive in Vim with Clojure, described below:</p>
<div class="section" id="vim-fireplace">
<h2>Vim-Fireplace</h2>
<p><a class="reference external" href="https://github.com/tpope/vim-fireplace">Vim-fireplace</a> connects to a Clojure
REPL instance from within Vim.</p>
<p>Some key commands:</p>
<table border="1" class="docutils">
<colgroup>
<col width="16%"/>
<col width="84%"/>
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Command</th>
<th class="head">Function</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><cite>cpp</cite></td>
<td>Execute the current form.</td>
</tr>
<tr class="row-odd"><td><cite>cpr</cite></td>
<td>Reload the current file.</td>
</tr>
<tr class="row-even"><td><cite>K</cite></td>
<td>Lookup help for command that the cursor is
under.</td>
</tr>
<tr class="row-odd"><td><cite>[d</cite></td>
<td>Lookup source that the command is under.</td>
</tr>
</tbody>
</table>
<p>It works well, but i need to figure out a way to ensure that the REPL buffer is
always open as the popping open of the buffer grows old quickly.</p>
</div>
<div class="section" id="vim-slime">
<h2>Vim-slime</h2>
<p>A solution which uses the excellent Tmux is <a class="reference external" href="https://github.com/jpalardy/vim-slime">vim-slime</a>, a nice setup is described in this
<a class="reference external" href="http://michaelalynmiller.com/blog/2013/02/27/vim-tmux-clojure">blog</a>. It
works with any REPL. In brief you open a Clojure REPL in a Tmux window and tell
Vim to send highlighted lines. It’s good as the REPL window remains open
showing the command execution history.</p>
<p>Some key commands:</p>
<table border="1" class="docutils">
<colgroup>
<col width="44%"/>
<col width="56%"/>
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Command</th>
<th class="head">Function</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><cite>C-c, C-c</cite></td>
<td>Send line to Tmux window with REPL.</td>
</tr>
<tr class="row-odd"><td><cite>&lt;highlight lines&gt; C-c, C-c</cite></td>
<td>Send line to Tmux window with REPL.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="conclusion">
<h2>Conclusion</h2>
<p>A combination of both of the above works really well. I use Vim-Fireplace in
order to get contextual help and Vim-slime to execute code. Once i figure out
how to have a consistent buffer open in vim-fireplace then i guess i’ll ditch
vim-slime.</p>
</div>
]]></description>
             <pubDate>Fri, 28 Feb 2014 00:00:00 +0000</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2014/02/20/nowcast_this.html</link>
            <guid>http://wachunga.com/2014/02/20/nowcast_this.html</guid>
            <title><![CDATA[Nowcast this]]></title>
            <description><![CDATA[<h1>Nowcast this</h1>
<p>Nowcasting is a technique which has recently gained popularity in economics.
Essentially low frequency economic variables are foretasted by a series of
higher frequency variables in state space. The canonical example is that of
predicting GDP figures (low frequency of data release) from higher frequency
variables such as jobless figures, industrial orders and trade balance.</p>
<p>Such a model can be written as a system of two equations:</p>
<ul>
<li><p class="first">measurement equations linking observed series to latent variable (or state
process)</p>
<blockquote>
<div><div class="math">
\[Y_t^{K_Y} = \mu + \zeta(\Theta)X_t + G_t\]</div>
</div></blockquote>
</li>
<li><p class="first">transistion equations describing the state process dynamics</p>
<blockquote>
<div><div class="math">
\[X_t = \phi(\Theta)X_{t-1} + H_t\]</div>
</div></blockquote>
</li>
</ul>
<p>where in the above equations <span class="math">\(Y_t^{K_Y}\)</span> is the vector of observed
variables and <span class="math">\(X_t\)</span> is the unobserved state variables, the dynamics of
which are explained by the transition equation.</p>
<p><span class="math">\(G_t\)</span> and <span class="math">\(H_t\)</span> represent covariance matrices of the disturbances
and <span class="math">\(\phi(\Theta)\)</span> and <span class="math">\(\zeta(\Theta)\)</span> represent matrices of the
coefficients. The covariance matrices are determined from an iterative
Expectation-Maiximisation algorithm.</p>
<p>As the model is in state-space we can now gain projections for both the
observed and the predicted variables using the Kalman filter, as well as
allowing us to have missing variables in our series.</p>
<p>It’s an interesting approach as the forecast for the low-frequency variable
gets progressively more accurate as more data is released as we move closer to
the announcement date. This means that there is a <cite>news</cite> component or
“unexpected” component which we obtain from the model as the long-term (or
indeed short-term) variables have their forecast updated, which is could be a
useful signal.</p>
<p>A <a class="reference external" href="http://www.ecb.europa.eu/pub/pdf/scpwps/ecbwp1564.pdf">paper</a> by Marta Bańbura, Domenico Giannone, Michele Modugno and Lucrezia
Reichlin reviewing the approaches can be found on the ECB website.</p>
]]></description>
             <pubDate>Thu, 20 Feb 2014 00:00:00 +0000</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2014/02/18/hal_r_varian.html</link>
            <guid>http://wachunga.com/2014/02/18/hal_r_varian.html</guid>
            <title><![CDATA[Hal R. Varian]]></title>
            <description><![CDATA[<h1>Hal R. Varian</h1>
<p>In my quest to keep upto date with the big ideas in econometrics and finance I
happened upon Hal R. Varian. Hal is both a professor at UC Berkley and also
Chief Economist at Google, a couple of impressive positions held simultaneously
positions held simultaneously.</p>
<p>There is a trove of Hal’s essays and papers available <a class="reference external" href="http://people.ischool.berkeley.edu/~hal/people/hal/papers.html">here</a>, I
particularly enjoyed his <a class="reference external" href="http://people.ischool.berkeley.edu/~hal/Papers/2013/BeyondBigDataPaperFINAL.pdf">comment on big data in economics</a>
which essentially espouses economists to not only analyse the electronic data
that pretty much any firm is amassing but also to perform experiments within
the bounds of the collection system, giving rise to similar advances as have
been gained from similar methods applied to e-marketing (see <a class="reference external" href="http://www.kalzumeus.com/greatest-hits">Patrick McKenzie’s
essays</a> for more).</p>
<p>Another paper of note was <a class="reference external" href="http://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf">Predicting the Present with Bayesian Strucural Time
Series</a>
(or see the <a class="reference external" href="http://people.ischool.berkeley.edu/~hal/Papers/2012/fat-talk.pdf">slides</a> for an
abbreviated view) in which is described a system for economic nowcasting using
a system where terms correlated to an economic variable e.g. claims for
unemployment, are discovered with Google Correlate and then Google Trends
data for those terms is analysed and ranked in terms of predictability using a
Markov chain Monte Carlo (MCMC) algorithm - interesting!</p>
]]></description>
             <pubDate>Tue, 18 Feb 2014 00:00:00 +0000</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2014/02/06/beige_book_sentiment.html</link>
            <guid>http://wachunga.com/2014/02/06/beige_book_sentiment.html</guid>
            <title><![CDATA[Beige Book Sentiment]]></title>
            <description><![CDATA[<h1>Beige Book Sentiment</h1>
<div class="figure align-center">
<img alt="../../../_images/beige_book_word_cloud.png" src="http://wachunga.com/_images/beige_book_word_cloud.png"/>
<p class="caption">Word cloud showing relative frequencies of words in all Beige Books since
1970</p>
</div>
<div class="section" id="why">
<h2>Why?</h2>
<p>Behavioural finance has provided proof that financial decisions are
significantly driven by emotion and mood [1].</p>
<p>Therefore if we can gauge the mood of policy makers, perhaps we can gauge
policy decision.</p>
<p>Rochester Cahan, VP of Global Equity Quantitative Strategy at Deutsche Bank,
states that the sentiment scores of Thomson Reuters (powered by Lexalytics) are
uncorrelated with traditional quantitative signals [2].</p>
</div>
<div class="section" id="commercial-products-and-funds">
<h2>Commercial Products and Funds</h2>
<p>There are a number of commercial products and funds already providing or
exploiting sentiment based signals.</p>
<p>Thompson Reuters recently acquired <a class="reference external" href="http://www.lexalytics.com">Lexalytics</a>
who provide sentiment indicators in machine readable format. Global sentiment
indicators are also provided by <a class="reference external" href="https://ww.marketpsych.com">MarketPsych</a>, a
spin off company from the now closed MarketPsych Captial fund setup by <a class="reference external" href="http://www.richard.peterson.net">Richard
Peterson MD</a> who reported a 28% return from
Sept. 2, 2008, through Dec. 31, 2010 while the S&amp;P 500 lost 1.6 percent over
the same period.</p>
<p>Cayman Atlantic, aka the “Twitter Hedge Fund” is probably the most high profile
use case of sentiment analysis. Founded by Paul Hawtin in 2013 the fund works
closely with the team behind the paper <a class="reference external" href="http://arxiv.org/pdf/1010.3003&amp;">Twitter Mood Predicts the Stock Market
(pre-print)</a> [3] in order to gauge the
entire Twitter verse in terms of 6 different moods: calm, alert, sure, vital,
kind, happy. They found that predominately only the calm mood was Granger
causative with DJIA.</p>
</div>
<div class="section" id="sentiment-from-the-beige-book">
<h2>Sentiment from the Beige Book</h2>
<ul class="simple">
<li>Beige Book content downloaded pro programmatically since 1970.</li>
<li>Text cleaned and put into common format.</li>
</ul>
<a class="reference internal image-reference" href="http://wachunga.com/_images/beige_book_words.png"><img alt="../../../_images/beige_book_words.png" src="http://wachunga.com/_images/beige_book_words.png" style="width: 600px;"/></a>
<ul>
<li><dl class="first docutils">
<dt>Text analysed with Pythons NLTK for sentiment using two dictionaries:</dt>
<dd><ul class="first last simple">
<li>Harvard IV-4</li>
<li>Loughran and McDonald Financial Sentiment</li>
</ul>
</dd>
</dl>
</li>
</ul>
<p><strong>Polarity</strong> (P) is defined as:</p>
<div class="math">
\[P = \frac{N_{pos}-N_{neg}}{N_{pos}+N_{neg}}\]</div>
<p><strong>Subjectivity</strong> (S) is defined as:</p>
<div class="math">
\[S = \frac{N_{pos}+N_{neg}}{N}\]</div>
<p>With the Beige Book data set we get the following:</p>
<a class="reference internal image-reference" href="http://wachunga.com/_images/beige_book_subjectivity.png"><img alt="../../../_images/beige_book_subjectivity.png" src="http://wachunga.com/_images/beige_book_subjectivity.png" style="width: 600px;"/></a>
<a class="reference internal image-reference" href="http://wachunga.com/_images/beige_book_polarity.png"><img alt="../../../_images/beige_book_polarity.png" src="http://wachunga.com/_images/beige_book_polarity.png" style="width: 600px;"/></a>
<p>From the above we can see the differences in the two dictionaries used to
evaluate Sentiment. The Harvard IV-4 dictionary has no concept of financial
lexicon whereas the Loughran and McDonald Financial Sentiment is calibrated
from 10-K file date returns, post-file date returns, return volatility,
allegations of accounting fraud, and company material weakness disclosures, and
as such is more evenly weighted around 0 for Polarity.</p>
<p>Comparing the Loughran and McDonald Financial Sentiment with T-Bill discount
rates gives the following:</p>
<a class="reference internal image-reference" href="http://wachunga.com/_images/beige_book_sentiment_tbill.png"><img alt="../../../_images/beige_book_sentiment_tbill.png" src="http://wachunga.com/_images/beige_book_sentiment_tbill.png" style="width: 600px;"/></a>
<p>By inspection of the above it appears there is some causality/correlation
between sentiment of the Beige Book and the T-bill discount rate. Soon i will
publish statistical analysis of this causality (Granger or otherwise).</p>
<p>For more info. on this experiment please get in touch, <a class="reference external" href="mailto:chris.j.morgan%40gmail.com">chris<span>.</span>j<span>.</span>morgan<span>@</span>gmail<span>.</span>com</a>.</p>
</div>
<div class="section" id="references">
<h2>References</h2>
<p>[1] J.R. Nofsinger, Social mood and financial economics, Journal of Behaviour
Finance 6 (3) (2005) 144–160.</p>
<p>[2] <a class="reference external" href="http://strata.oreilly.com/2011/05/sentiment-analysis-finance.html">http://strata.oreilly.com/2011/05/sentiment-analysis-finance.html</a></p>
<p>[3] Johan Bollen, Huina Mao, Xiao-Jun Zeng: Twitter mood predicts the stock market.
J. Comput. Science 2(1): 1-8 (2011)</p>
</div>
]]></description>
             <pubDate>Thu, 06 Feb 2014 00:00:00 +0000</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2014/01/13/remember_vim_folding.html</link>
            <guid>http://wachunga.com/2014/01/13/remember_vim_folding.html</guid>
            <title><![CDATA[Remember Vim folding]]></title>
            <description><![CDATA[<h1>Remember Vim folding</h1>
<table border="1" class="docutils">
<colgroup>
<col width="11%"/>
<col width="89%"/>
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Key</th>
<th class="head">Operation</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>zO</td>
<td>Open all folds recursivley</td>
</tr>
<tr class="row-odd"><td>zo</td>
<td>Open one fold</td>
</tr>
<tr class="row-even"><td>zc</td>
<td>Close one fold</td>
</tr>
<tr class="row-odd"><td>zC</td>
<td>Close all folds recursivley</td>
</tr>
<tr class="row-even"><td>za</td>
<td>Toggle fold</td>
</tr>
<tr class="row-odd"><td>zA</td>
<td>Toggle fold recursivley</td>
</tr>
<tr class="row-even"><td>zR</td>
<td>Open all folds</td>
</tr>
<tr class="row-odd"><td>zM</td>
<td>Close all folds</td>
</tr>
</tbody>
</table>
<p>Then i set the following in .vimrc:</p>
<div class="highlight-python"><div class="highlight"><pre>" folding
" toggle open fold
nnoremap f zA
" open all
nnoremap F zR
" clos all
nnoremap &lt;C-f&gt; zM
</pre></div>
</div>
]]></description>
             <pubDate>Mon, 13 Jan 2014 00:00:00 +0000</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2014/01/05/being_productive_with_ipython_notebooks.html</link>
            <guid>http://wachunga.com/2014/01/05/being_productive_with_ipython_notebooks.html</guid>
            <title><![CDATA[Being even more productive with IPython notebooks]]></title>
            <description><![CDATA[<h1>Being even more productive with IPython notebooks</h1>
<p>IPython notebooks are an awesome tool for exploring data. Currently there are a
few issues with the software which the community are working through.</p>
<div class="section" id="slides">
<h2>Slides</h2>
<p>Particularly useful is the ability to be able to create slides from your
notebooks using reveal.js:</p>
<div class="highlight-bash"><div class="highlight"><pre>python3 nbconvert --to slides BeigeBook.ipynb --post serve
</pre></div>
</div>
<p>But we need to follow these steps in order for the formatting to work
correctly:</p>
<ol class="arabic simple">
<li>Add this custom.css file: <a class="reference external" href="https://gist.github.com/damianavila/6211198">https://gist.github.com/damianavila/6211198</a></li>
<li>Run this little snippet: <a class="reference external" href="https://gist.github.com/damianavila/6211211">https://gist.github.com/damianavila/6211211</a></li>
<li>Add ?print.pdf to the end of the url</li>
<li>Print to pdf, use Landscape orientation</li>
</ol>
</div>
<div class="section" id="git">
<h2>Git</h2>
<p>The JSON format of IPython notebooks is great, however there is no need to save Base64 encoded binary data in Git. We can strip out the binary blobs with Git filters.  Add the following somewhere on your path: <a class="reference external" href="https://github.com/cfriedline/ipynb_template/blob/master/nbstripout">https://github.com/cfriedline/ipynb_template/blob/master/nbstripout</a>, then add the following in <span class="docutils literal"><span class="pre">.git/config</span></span>:</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="o">[</span>filter <span class="s2">"stripoutput"</span><span class="o">]</span>
    <span class="nv">clean</span> <span class="o">=</span> <span class="s2">"/path/to/nbstripout"</span>
</pre></div>
</div>
<p>And a <span class="docutils literal"><span class="pre">.gitattributes</span></span> file in your project root with the following contents:</p>
<div class="highlight-bash"><div class="highlight"><pre>*.ipynb <span class="nv">filter</span><span class="o">=</span>stripoutput
</pre></div>
</div>
<p>You will not notice any changes to your local <span class="docutils literal"><span class="pre">.ipynb</span></span> file when you commit (as the content is being filtered, not replaced as a pre-commit hook would do). Once committed, delete the file and checkout again and you will see a <span class="docutils literal"><span class="pre">.ipynb</span></span> file sans output. Also the numbering of cells will start continuously from 1 - great!</p>
</div>
]]></description>
             <pubDate>Sun, 05 Jan 2014 00:00:00 +0000</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2014/01/03/setup_matlab.html</link>
            <guid>http://wachunga.com/2014/01/03/setup_matlab.html</guid>
            <title><![CDATA[Setting up MATLAB contexts]]></title>
            <description><![CDATA[<h1>Setting up MATLAB contexts</h1>
<p>If you are forced to use MATLAB (here’s a whole blog devoted to the topic of
why not to use it <a class="reference external" href="http://abandonmatlab.wordpress.com">http://abandonmatlab.wordpress.com/</a>) the following advice
maybe useful for easily managing your path and hence creating contexts of work.</p>
<p>In cases where Administrator privileges are not held, the following config. is
flexible.</p>
<p>Define MATLAB’s <span class="docutils literal"><span class="pre">userpath</span></span> to be a user writeable directory. This is the initial
directory MATLAB will parse.</p>
<p>Within the <span class="docutils literal"><span class="pre">userpath</span></span> create <span class="docutils literal"><span class="pre">startup.m</span></span>:</p>
<div class="highlight-matlab"><div class="highlight"><pre><span class="k">if</span> <span class="o">~</span><span class="n">isdeployed</span>
    <span class="n">path</span><span class="p">(</span><span class="n">my_path</span><span class="p">)</span>
    <span class="n">set_vars</span>
</pre></div>
</div>
<p>Where <span class="docutils literal"><span class="pre">my_path</span></span> is a matlab file which sets the path like:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">function</span> <span class="n">p</span> <span class="o">=</span> <span class="n">my_path</span>
     <span class="n">p</span> <span class="o">=</span> <span class="p">[</span><span class="s">'/home/chris/matlab;'</span><span class="p">,</span> <span class="s">'/home/chris/important;'</span><span class="p">];</span>
     <span class="n">cd</span><span class="p">(</span><span class="s">'/home/chris/matlab'</span><span class="p">);</span>
<span class="n">end</span>
</pre></div>
</div>
<p>So we set the path and cd to a relevant directory. Also in the userpath folder,
one can keep many files like <span class="docutils literal"><span class="pre">my_path.m</span></span>, which define different contexts to
work in, making changing contexts as easy as:</p>
<div class="highlight-matlab"><div class="highlight"><pre><span class="n">path</span><span class="p">(</span><span class="n">my_other_path</span><span class="p">)</span>
</pre></div>
</div>
<p>Whithin each context <span class="docutils literal"><span class="pre">path</span></span> file if you also call the <span class="docutils literal"><span class="pre">set_vars</span></span> script,
this allows <span class="docutils literal"><span class="pre">set_vars</span></span> to contain useful variables e.g. paths to output
directories and the like.</p>
]]></description>
             <pubDate>Fri, 03 Jan 2014 00:00:00 +0000</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2013/05/01/common_operations_in_pandas.html</link>
            <guid>http://wachunga.com/2013/05/01/common_operations_in_pandas.html</guid>
            <title><![CDATA[Common operations in Pandas]]></title>
            <description><![CDATA[<h1>Common operations in Pandas</h1>
<p>This is another “do not forget” post.</p>
<p>If you munge data in Python then you really should be using <a class="reference external" href="http://pandas.pydata.org">Pandas</a>. These are some notes about common operations.</p>
<div class="section" id="hierachical-index">
<h2>Hierachical index</h2>
<p>Given a set of data like this (refered to as Table A):</p>
<blockquote>
<div><table border="1" class="docutils">
<colgroup>
<col width="36%"/>
<col width="16%"/>
<col width="16%"/>
<col width="16%"/>
<col width="17%"/>
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"> </th>
<th class="head">Bid</th>
<th class="head">Mid</th>
<th class="head">Offer</th>
<th class="head">Variable</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1994-01-03 16:00:00</td>
<td>0.9980</td>
<td>0.9981</td>
<td>0.9981</td>
<td>ARS</td>
</tr>
<tr class="row-odd"><td>1994-01-03 16:00:00</td>
<td>12.2190</td>
<td>12.2215</td>
<td>12.2240</td>
<td>ATS</td>
</tr>
<tr class="row-even"><td>1994-01-03 16:00:00</td>
<td>0.6835</td>
<td>0.6838</td>
<td>0.6840</td>
<td>AUD</td>
</tr>
<tr class="row-odd"><td>1994-01-03 16:00:00</td>
<td>39.0000</td>
<td>39.0000</td>
<td>39.0000</td>
<td>BDT</td>
</tr>
<tr class="row-even"><td>1994-01-03 16:00:00</td>
<td>36.2060</td>
<td>36.2425</td>
<td>36.2790</td>
<td>BEF</td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>It often makes more sense to represent it as a hierachical index (referred to as Table B), e.g.</p>
<blockquote>
<div><table border="1" class="docutils">
<colgroup>
<col width="36%"/>
<col width="17%"/>
<col width="16%"/>
<col width="16%"/>
<col width="16%"/>
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"> </th>
<th class="head"> </th>
<th class="head">Bid</th>
<th class="head">Mid</th>
<th class="head">Offer</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>index</td>
<td>Variable</td>
<td> </td>
<td> </td>
<td> </td>
</tr>
<tr class="row-odd"><td>1994-01-03 16:00:00</td>
<td>ARS</td>
<td>0.9980</td>
<td>0.9981</td>
<td>0.9981</td>
</tr>
<tr class="row-even"><td> </td>
<td>ATS</td>
<td>12.2190</td>
<td>12.2215</td>
<td>12.2240</td>
</tr>
<tr class="row-odd"><td> </td>
<td>AUD</td>
<td>0.6835</td>
<td>0.6838</td>
<td>0.6840</td>
</tr>
<tr class="row-even"><td> </td>
<td>BDT</td>
<td>39.0000</td>
<td>39.0000</td>
<td>39.0000</td>
</tr>
<tr class="row-odd"><td> </td>
<td>BEF</td>
<td>36.2060</td>
<td>36.2425</td>
<td>36.2790</td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>This can be done for a pandas.DataFrame <span class="docutils literal"><span class="pre">df</span></span> like so</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s">'index'</span><span class="p">,</span> <span class="s">'Variable'</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="subset-of-columns-and-a-pivot">
<h2>Subset of columns and a pivot</h2>
<p>Consider again Table A above loaded as <span class="docutils literal"><span class="pre">df</span></span>, if we wish to filter out a
subset of values in the <span class="docutils literal"><span class="pre">Variable</span></span> column, and consider the <span class="docutils literal"><span class="pre">Mid</span></span> values
only for then we can do the following to have a continuous time series:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">g10_set</span> <span class="o">=</span> <span class="p">[</span>
<span class="s">'USD'</span><span class="p">,</span> <span class="s">'EUR'</span><span class="p">,</span> <span class="s">'JPY'</span><span class="p">,</span> <span class="s">'CHF'</span><span class="p">,</span> <span class="s">'GBP'</span><span class="p">,</span> <span class="s">'AUD'</span><span class="p">,</span> <span class="s">'CAD'</span><span class="p">,</span> <span class="s">'SEK'</span><span class="p">,</span>
<span class="s">'NOK'</span><span class="p">,</span> <span class="s">'NZD'</span>
<span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'Variable'</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">g10_set</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span>
    <span class="n">index</span><span class="o">=</span><span class="s">'index'</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s">'Variable'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="s">'Mid'</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Which results in Table C:</p>
<blockquote>
<div><table border="1" class="docutils">
<colgroup>
<col width="26%"/>
<col width="10%"/>
<col width="10%"/>
<col width="10%"/>
<col width="6%"/>
<col width="10%"/>
<col width="11%"/>
<col width="10%"/>
<col width="7%"/>
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Variable</th>
<th class="head">AUD</th>
<th class="head">CAD</th>
<th class="head">CHF</th>
<th class="head">EUR</th>
<th class="head">GBP</th>
<th class="head">JPY</th>
<th class="head">NOK</th>
<th class="head"> </th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>index</td>
<td> </td>
<td> </td>
<td> </td>
<td> </td>
<td> </td>
<td> </td>
<td> </td>
<td> </td>
</tr>
<tr class="row-odd"><td>1994-01-03 16:00:00</td>
<td>0.6838</td>
<td>1.3143</td>
<td>1.4827</td>
<td>NaN</td>
<td>1.4805</td>
<td>112.395</td>
<td>7.5251</td>
<td> </td>
</tr>
<tr class="row-even"><td>1994-01-04 16:00:00</td>
<td>0.6848</td>
<td>1.3164</td>
<td>1.4861</td>
<td>NaN</td>
<td>1.4819</td>
<td>113.155</td>
<td>7.5259</td>
<td> </td>
</tr>
<tr class="row-odd"><td>1994-01-05 16:00:00</td>
<td>0.6873</td>
<td>1.3153</td>
<td>1.4800</td>
<td>NaN</td>
<td>1.4864</td>
<td>112.760</td>
<td>7.5020</td>
<td> </td>
</tr>
<tr class="row-even"><td>1994-01-06 16:00:00</td>
<td>0.6843</td>
<td>1.3220</td>
<td>1.4745</td>
<td>NaN</td>
<td>1.4880</td>
<td>112.555</td>
<td>7.4903</td>
<td> </td>
</tr>
<tr class="row-odd"><td>1994-01-07 16:00:00</td>
<td>0.6868</td>
<td>1.3225</td>
<td>1.4705</td>
<td>NaN</td>
<td>1.4905</td>
<td>111.825</td>
<td>7.4865</td>
<td> </td>
</tr>
</tbody>
</table>
</div></blockquote>
</div>
<div class="section" id="working-with-the-index">
<h2>Working with the index</h2>
<p>To extract indexed data points which are common to df1 from df2, you can do the
following:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">df2</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="n">df1</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
</pre></div>
</div>
<p>To extract ranges of index from df2, the DataFrame may be sliced:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># extract ranges of index</span>
<span class="n">df2</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="n">df1</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">df1</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>

<span class="c"># and similarly specific values may also be accesed, pandas will coerce</span>
<span class="c"># these to pd.Timestamp</span>
<span class="n">df2</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="s">'2013-12-31 16:00:00'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="other-bits-and-bobs">
<h2>Other bits and bobs</h2>
<ul class="simple">
<li>Find row where value of column is max: <span class="docutils literal"><span class="pre">df['AUD'].argmax()</span></span></li>
<li>Find indexes of null values <span class="docutils literal"><span class="pre">pd.isnull(df).any(1).nonzero()</span></span> which is
utilising the <span class="docutils literal"><span class="pre">nonzero</span></span> numpy object, i.e. return indicies of elements
which are nonzero.</li>
</ul>
</div>
]]></description>
             <pubDate>Wed, 01 May 2013 00:00:00 +0100</pubDate>
        </item>
    
        <item>
            <link>http://wachunga.com/2013/04/12/ipython_notes.html</link>
            <guid>http://wachunga.com/2013/04/12/ipython_notes.html</guid>
            <title><![CDATA[IPython notes]]></title>
            <description><![CDATA[<h1>IPython notes</h1>
<p>This is a post to jog my memory when needed.</p>
<p>IPython saves all it’s hisotry in a SQLite database. This is super useful for
recovering commnads from an interactive programming session.</p>
<p>Imagine you forgot to save some dataset manipulation (loading tabdeliminated
csv into a DataFrame), you can easily recover that analysis:</p>
<p>Find the command which used the Pandas read_table</p>
<div class="highlight-python"><div class="highlight"><pre>In [1]: %history -g read_table
173/5: df = pd.io.parsers.read_table(fname, header=6)
173/9: pd.io.parsers.read_table?
173/10: df = pd.io.parsers.read_table(fname, header=6, index_col=0)
173/12: df = pd.io.parsers.read_table(fname, header=6, index_col=0, parse_dates=True)
</pre></div>
</div>
<p>Export a chunk of that history to a file for editing:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="o">%</span><span class="n">history</span> <span class="mi">173</span><span class="o">/</span><span class="mi">12</span><span class="o">-</span><span class="mi">2000</span> <span class="o">-</span><span class="n">f</span> <span class="n">hist</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>Then after editing the file <span class="docutils literal"><span class="pre">hist.py</span></span> run this inside your currency IPython
session with <span class="docutils literal"><span class="pre">run</span> <span class="pre">-i</span> <span class="pre">hist.py</span></span> (where the <span class="docutils literal"><span class="pre">-i</span></span> indicated running the script
inside the current sessions namespace).</p>
<p>Sweeet!</p>
]]></description>
             <pubDate>Fri, 12 Apr 2013 00:00:00 +0100</pubDate>
        </item>
    
    </channel>
</rss>